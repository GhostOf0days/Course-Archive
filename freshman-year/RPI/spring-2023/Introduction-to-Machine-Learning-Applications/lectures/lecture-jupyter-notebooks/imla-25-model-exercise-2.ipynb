{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRlGzpOI8eO0"
   },
   "source": [
    "\n",
    "[![AnalyticsDojo](https://github.com/rpi-techfundamentals/spring2019-materials/blob/master/fig/final-logo.png?raw=1)](http://rpi.analyticsdojo.com)\n",
    "<center><h1>Titanic Classification - Challenge Solutions</h1></center>\n",
    "<center><h3><a href = 'http://introml.analyticsdojo.com'>introml.analyticsdojo.com</a></h3></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XovA71E3XFM"
   },
   "source": [
    "# Titanic Classification - Challenge Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7pW1UhJT8ePk"
   },
   "source": [
    "As an example of how to work with both categorical and numerical data, we will perform survival predicition for the passengers of the HMS Titanic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1633030034621,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "bvj3Wids8ePm",
    "outputId": "22f4ca66-cb77-4d3b-9b33-0323b0c46a10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object') Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/input/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/rpi-techfundamentals/spring2019-materials/master/input/test.csv')\n",
    "\n",
    "print(train.columns, test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xqjk2-P8ePp"
   },
   "source": [
    "Here is a broad description of the keys and what they mean:\n",
    "\n",
    "```\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "boat            Lifeboat\n",
    "body            Body Identification Number\n",
    "home.dest       Home/Destination\n",
    "```\n",
    "\n",
    "In general, it looks like `name`, `sex`, `cabin`, `embarked`, `boat`, `body`, and `homedest` may be candidates for categorical features, while the rest appear to be numerical features. We can also look at the first couple of rows in the dataset to get a better understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1633030034849,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "bqmMR9G78ePr",
    "outputId": "ba36fc0c-c5de-464c-9e6f-6037fb62703a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54WY6zD78ePv"
   },
   "source": [
    "### Preprocessing function\n",
    "\n",
    "We want to create a preprocessing function that can address transformation of our train and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1633030034850,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "FKX26KU34Ti6",
    "outputId": "1a2d2d94-b89b-4622-f16b-3abc25332190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values before processing: 179\n",
      "Total missing values after processing: 0\n",
      "Total missing values before processing: 87\n",
      "Total missing values after processing: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minor/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n",
      "/Users/minor/opt/anaconda3/lib/python3.9/site-packages/pandas/core/algorithms.py:798: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  uniques = Index(uniques)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "cat_features = ['Pclass', 'Sex', 'Embarked']\n",
    "num_features =  [ 'Age', 'SibSp', 'Parch', 'Fare'  ]\n",
    "\n",
    "\n",
    "def preprocess(df, num_features, cat_features, dv):\n",
    "    features = cat_features + num_features\n",
    "    if dv in df.columns:\n",
    "      y = df[dv]\n",
    "    else:\n",
    "      y=None \n",
    "    #Address missing variables\n",
    "    print(\"Total missing values before processing:\", df[features].isna().sum().sum() )\n",
    "  \n",
    "    imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    df[cat_features]=imp_mode.fit_transform(df[cat_features] )\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    df[num_features]=imp_mean.fit_transform(df[num_features])\n",
    "    print(\"Total missing values after processing:\", df[features].isna().sum().sum() )\n",
    "   \n",
    "    X = pd.get_dummies(df[features], columns=cat_features, drop_first=True)\n",
    "    return y,X\n",
    "\n",
    "y, X =  preprocess(train, num_features, cat_features, 'Survived')\n",
    "test_y, test_X = preprocess(test, num_features, cat_features, 'Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bV5s-bSMJPne"
   },
   "source": [
    "### Train Test Split\n",
    "\n",
    "Now we are ready to model. We are going to separate our Kaggle given data into a \"Train\" and a \"Validation\" set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1633030034850,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "icKFkwZQpvCs"
   },
   "outputs": [],
   "source": [
    "#Import Module\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=122,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1633030034850,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "oAUV7oYp7HZV",
    "outputId": "e9574a30-5268-4fbe-e4aa-67a56a4d73c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38362760834670945 0.3843283582089552\n"
     ]
    }
   ],
   "source": [
    "print(train_y.mean(), val_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1633030034851,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "jGoUxc7brPIg"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1633030034851,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "6kHwslmYrcRw",
    "outputId": "e9924394-8c68-49df-e1d4-ae025c725c6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics score train:  0.8202247191011236\n",
      "Metrics score validation:  0.8432835820895522\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "classifier = tree.DecisionTreeClassifier(max_depth=4)\n",
    "#This fits the model object to the data.\n",
    "classifier.fit(train_X, train_y)\n",
    "#This creates the prediction. \n",
    "train_y_pred = classifier.predict(train_X)\n",
    "val_y_pred = classifier.predict(val_X)\n",
    "test['Survived'] = classifier.predict(test_X)\n",
    "print(\"Metrics score train: \", metrics.accuracy_score(train_y, train_y_pred) )\n",
    "print(\"Metrics score validation: \", metrics.accuracy_score(val_y, val_y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1633030034851,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "z8iumL96KuJM",
    "outputId": "20c1c218-b7e0-48d7-f39e-c02cc76abb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics score train:  0.698744769874477\n",
      "Metrics score validation:  0.7572815533980582\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics score train: \", metrics.recall_score(train_y, train_y_pred) )\n",
    "print(\"Metrics score validation: \", metrics.recall_score(val_y, val_y_pred) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRgnvFfRJnzF"
   },
   "source": [
    "### Outputting Probabilities\n",
    "Some evaluation metrics (like the [Area Under the Receiver Operating Characteristic Curve (ROC AUC)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html) take the probability rather than the class which is output by the model.  \n",
    "\n",
    "\n",
    "The function `predict_proba` outputs the probability of each class. Here, we want only the second value which is the probability of survived.\n",
    "\n",
    "\n",
    "**When working with a new evaluation metric, always check to see whether it takes the probability or the class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1633030034851,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "pTBPKwA28_Ee"
   },
   "outputs": [],
   "source": [
    "train_y_pred_prob = classifier.predict_proba(train_X)[:,1]\n",
    "val_y_pred_prob = classifier.predict_proba(val_X)[:,1]\n",
    "test_y_pred_prob = classifier.predict_proba(test_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1633030034852,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "jElhvqo_8Woa",
    "outputId": "04a702c9-fcfb-472e-86fa-6dfa4e35c34f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics score train:  0.8719763336820084\n",
      "Metrics score validation:  0.8686672550750221\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics score train: \", metrics.roc_auc_score(train_y, train_y_pred_prob) )\n",
    "print(\"Metrics score validation: \", metrics.roc_auc_score(val_y, val_y_pred_prob) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JrJQAqMwJY5"
   },
   "source": [
    "## Challenge\n",
    "Create a function that can accept any Scikit learn model and assess the perfomance in the validation set, storing results as a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1633030034986,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "rXRikRZwvNMO"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Function Definition\n",
    "\n",
    "def evaluate(name, dtype, y_true, y_pred, y_prob, results=pd.Series(dtype=float)):\n",
    "  \"\"\"\n",
    "  This creates a Pandas series with different results. \n",
    "  \"\"\"\n",
    "  results['name']=name\n",
    "  results['accuracy-'+dtype]=metrics.accuracy_score(y_true, y_pred)\n",
    "  results['recall-'+dtype]=metrics.recall_score(y_true, y_pred)\n",
    "  results['auc-'+dtype]=metrics.roc_auc_score(y_true, y_prob)\n",
    "  return results\n",
    "\n",
    "\n",
    "def train_evaluate(name, classifier, train_X, train_y, val_X, val_y):\n",
    "  \"\"\"\n",
    "  This will train and evaluate a classifier. \n",
    "  \"\"\"\n",
    "  classifier.fit(train_X, train_y)\n",
    "  #This creates the prediction. \n",
    "  r1= evaluate(name, \"train\", train_y, classifier.predict(train_X), classifier.predict_proba(train_X)[:,1])\n",
    "  r1= evaluate(name,\"validation\", val_y, classifier.predict(val_X), classifier.predict_proba(val_X)[:,1], results=r1)\n",
    "  return r1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HO84ymv4HSMD"
   },
   "source": [
    "## Analyze Multiple Models\n",
    "\n",
    "This code will model all values which are in the dictionary. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1633030035193,
     "user": {
      "displayName": "Jason Kuruzovich",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjiPRlSvj8SRdtKkRyzD6z5si2mFJGPGRrigI9D7Q=s64",
      "userId": "00154528308428981209"
     },
     "user_tz": 240
    },
    "id": "7oh4TGQcG1Z-",
    "outputId": "6f5d739d-b066-443b-895e-66fb2ee3763b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling:  knearest ...\n",
      "Modeling:  adaboost ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minor/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/minor/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/var/folders/0y/0vzl10290_qdfyzcwftxcg_h0000gn/T/ipykernel_48933/134998804.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final=final.append(results, ignore_index=True)\n",
      "/var/folders/0y/0vzl10290_qdfyzcwftxcg_h0000gn/T/ipykernel_48933/134998804.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final=final.append(results, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "       name  accuracy-train  accuracy-validation  auc-train  auc-validation  \\\n0  knearest        0.744783             0.712687   0.810610        0.781848   \n1  adaboost        0.821830             0.817164   0.896977        0.880229   \n\n   recall-train  recall-validation  \n0      0.506276           0.436893  \n1      0.744770           0.766990  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>accuracy-train</th>\n      <th>accuracy-validation</th>\n      <th>auc-train</th>\n      <th>auc-validation</th>\n      <th>recall-train</th>\n      <th>recall-validation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>knearest</td>\n      <td>0.744783</td>\n      <td>0.712687</td>\n      <td>0.810610</td>\n      <td>0.781848</td>\n      <td>0.506276</td>\n      <td>0.436893</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>adaboost</td>\n      <td>0.821830</td>\n      <td>0.817164</td>\n      <td>0.896977</td>\n      <td>0.880229</td>\n      <td>0.744770</td>\n      <td>0.766990</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=pd.DataFrame()\n",
    "# Other potential models: LogisticRegression, DecisionTreeClassifier, MLPClassifier\n",
    "allmodels={\"knearest\": KNeighborsClassifier(n_neighbors=10),\n",
    "           \"adaboost\":AdaBoostClassifier()}\n",
    "\n",
    "for key, value in  allmodels.items():\n",
    "  print(\"Modeling: \", key, \"...\")\n",
    "  results= train_evaluate(key, value, train_X, train_y, val_X, val_y)\n",
    "  final=final.append(results, ignore_index=True)\n",
    "final_order=['name','accuracy-train', 'accuracy-validation', 'auc-train', 'auc-validation','recall-train', 'recall-validation']\n",
    "final=final.loc[:,final_order]\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUorzaxdHmFO"
   },
   "source": [
    "### Challenge \n",
    "\n",
    "Augment the modeling to include [Random Forests](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) at multiple different hyperparameter levels. \n",
    "\n",
    "\n",
    "Augment the evaluation to include [Balanced Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html) and [F1](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) score.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "titanic-new.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/rpi-techfundamentals/website_fall_2021/blob/master/site/notebooks/nb-04-05-revisit-titanic.ipynb",
     "timestamp": 1632775130965
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
