{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4610bdb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe47fffcfdc463089d621e3ac42c3db4",
     "grade": false,
     "grade_id": "Desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Total points: 30 \n",
    "\n",
    "#### This will be graded towards Research Translation Exercise \n",
    "\n",
    "#### Please do not create nor modify any cells. Please write your code ONLY where it is required and submit your python notebook via LMS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45195799",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27e9fed4a5a5472fb72276d99edabedc",
     "grade": false,
     "grade_id": "data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please run this cell before answering the following questions \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lmanikon/lmanikon.github.io/master/teaching/datasets/RReviews.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf9689",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f97ac539320006185bcdf525b465117f",
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q1 [10 points]: Data preprocessing \n",
    "\n",
    "<ul>\n",
    "    <li> Split the data into two parts -- variable `X` that contains only features and variable `y` that contains the class label only. </li>\n",
    "    <li> You will notice that `X` will be a Pandas Series by now. Please use this to convert each value in X into lowercase. Once in lowercase, please remove all the non-alphanumeric characters in each review. </li>\n",
    "    <li> Create a new variable `cc` (can be a list) that includes the character count of each review. Please note that index should match with the index of reviews in `X`.</li>\n",
    "    <li> Create a new variable `wc` (can be a list) that includes the word count of each review. Please note that index should match with the index of reviews in `X`.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16902099",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0dc8aee6eec6f80e74d81cf31a0a2a3",
     "grade": false,
     "grade_id": "q1-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "import re\n",
    "\n",
    "cc=[]\n",
    "wc=[]\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a099e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3514526fa2e5adc43e52d26124b7f5d9",
     "grade": true,
     "grade_id": "1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(X)==type(y)\n",
    "assert len(X)==1000\n",
    "assert set(y)=={0,1}\n",
    "assert X[0]=='wow loved this place '\n",
    "assert cc[0]== 21\n",
    "assert cc[999]== 132\n",
    "assert wc[0]== 5\n",
    "assert wc[49]== 20\n",
    "assert round(np.mean(cc),2)==57.57\n",
    "assert round(np.mean(wc),2)==12.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d0d8b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88b6b1149463767924a447d40e856f69",
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2 [10 points]: Feature Generation\n",
    "\n",
    "<ul>\n",
    "    <li>Extract TFIDF vectors using the reviews in `X` and assign them to `newX`. Please note that all the modifications on reviews in the previous question should be reflected.</li>\n",
    "    <li>Use Principal Component Analysis to extract the top-300 PCs. Assign these top-300 PCs to variable `newX_pca`.</li>\n",
    "    <li>Standardize both `newX` and `newX_pca` and save them as `newX_std` and `newX_pca_std` respectively using StandardScaler function.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae18ee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9b5675a24b9d57bbea041364a639c17",
     "grade": false,
     "grade_id": "q2-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Standardization \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae11035",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5b0e46e07af70015a5f3b18516d89a7",
     "grade": true,
     "grade_id": "2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(newX.todense())==1000\n",
    "assert len(newX.todense()[0])==1\n",
    "assert round(np.mean(newX_std),2)==0\n",
    "assert len(newX_pca)==1000\n",
    "assert len(newX_pca[0])==300\n",
    "assert round(np.mean(newX_pca_std),2)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d1f44",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9fcbfc1c277b13a296f960b94f33e578",
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3 [10 points]: Building models using original set of features\n",
    "\n",
    "<ul>\n",
    "    <li>Use standardized data of original set of features ('newX_std') and class labels (`y`) to first perform train_test_split using `test_size`=0.3, `random_state`=10 to obtain X_train, X_test, y_train, y_test corresponding to training data of features, testing data of features, class labels for data points in training data, class labels for data points in testing data respectively.</li>\n",
    "    <li>Using `liblinear` as the solver, build a logistic regression model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_lg`. </li>\n",
    "    <li>Using max_depth=4, random_state=10, build a decision tree model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_dt`. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16675235",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e66aae40f8da8528097b3cec5141e96d",
     "grade": false,
     "grade_id": "q3-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "#Build logistic regression and decisiontree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391e5e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7626d2076f04976cc3ea06f9a39e566e",
     "grade": true,
     "grade_id": "3",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(acc_lg, 2)==0.77\n",
    "assert round(acc_dt, 2)<=0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5eda23",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b18d3c66b17c670269845cdc7149e0cd",
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4 [10 points]: Building models using top-300 principal component features\n",
    "\n",
    "<ul>\n",
    "    <li>Use standardized data of modified features as the top-300 principal components (`newX_pca_std`) and class labels (`y`) to first perform train_test_split using `test_size`=0.3, `random_state`=10 to obtain X_train, X_test, y_train, y_test corresponding to training data of features, testing data of features, class labels for data points in training data, class labels for data points in testing data respectively.</li>\n",
    "    <li>Using `liblinear` as the solver, build a logistic regression model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_pca_lg`. </li>\n",
    "    <li>Using max_depth=4, random_state=10, build a decision tree model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_pca_dt`. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b680d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c8c770db8a0053de8967a8927ddaf38",
     "grade": false,
     "grade_id": "q4-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "\n",
    "#Build logistic regression and decisiontree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc04ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3c18f63224160010cec27564d8240d3",
     "grade": true,
     "grade_id": "4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(acc_pca_lg, 2)<=0.80\n",
    "assert round(acc_pca_dt, 2)<=0.80"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
