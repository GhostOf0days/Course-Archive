{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4610bdb",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Total points: 30 \n",
    "\n",
    "#### This will be graded towards Research Translation Exercise \n",
    "\n",
    "#### Please do not create nor modify any cells. Please write your code ONLY where it is required and submit your python notebook via LMS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45195799",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please run this cell before answering the following questions \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lmanikon/lmanikon.github.io/master/teaching/datasets/RReviews.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf9689",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q1 [10 points]: Data preprocessing \n",
    "\n",
    "<ul>\n",
    "    <li> Split the data into two parts -- variable `X` that contains only features and variable `y` that contains the class label only. </li>\n",
    "    <li> You will notice that `X` will be a Pandas Series by now. Please use this to convert each value in X into lowercase. Once in lowercase, please remove all the non-alphanumeric characters in each review. </li>\n",
    "    <li> Create a new variable `cc` (can be a list) that includes the character count of each review. Please note that index should match with the index of reviews in `X`.</li>\n",
    "    <li> Create a new variable `wc` (can be a list) that includes the word count of each review. Please note that index should match with the index of reviews in `X`.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16902099",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "import re\n",
    "\n",
    "cc=[]\n",
    "wc=[]\n",
    "### BEGIN SOLUTION \n",
    "\n",
    "###First split the data into X -- feature set and y -- class label question\n",
    "\n",
    "\n",
    "X = df['Review']\n",
    "y = df['Liked']\n",
    "\n",
    "X = X.apply(lambda x:re.sub(r'\\W+', ' ', x.lower()))\n",
    "\n",
    "### Extract features now \n",
    "\n",
    "# - Number of characters\n",
    "# - Number of words\n",
    "cc = X.apply(lambda x:len(x))\n",
    "wc = X.apply(lambda x:len(x.split(' ')))\n",
    "\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0a099e",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "1",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(X)==type(y)\n",
    "assert len(X)==1000\n",
    "assert set(y)=={0,1}\n",
    "assert X[0]=='wow loved this place '\n",
    "assert cc[0]== 21\n",
    "assert cc[999]== 132\n",
    "assert wc[0]== 5\n",
    "assert wc[49]== 20\n",
    "assert round(np.mean(cc),2)==57.57\n",
    "assert round(np.mean(wc),2)==12.12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d0d8b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q2 [10 points]: Feature Generation\n",
    "\n",
    "<ul>\n",
    "    <li>Extract TFIDF vectors using the reviews in `X` and assign them to `newX`. Please note that all the modifications on reviews in the previous question should be reflected.</li>\n",
    "    <li>Use Principal Component Analysis to extract the top-300 PCs. Assign these top-300 PCs to variable `newX_pca`.</li>\n",
    "    <li>Standardize both `newX` and `newX_pca` and save them as `newX_std` and `newX_pca_std` respectively using StandardScaler function.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feae18ee",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#Standardization \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "newX = TfidfVectorizer().fit_transform(X)\n",
    "newX_std = StandardScaler().fit_transform(newX.todense())\n",
    "\n",
    "pca = PCA(n_components=300)\n",
    "newX_pca = pca.fit_transform(newX.todense())\n",
    "newX_pca_std = StandardScaler().fit_transform(newX_pca)\n",
    "\n",
    "#print(len(newX.todense()))\n",
    "#print(len(newX.todense()[0]))\n",
    "#print(round(np.mean(newX_std),2))\n",
    "\n",
    "#print(len(newX_pca))\n",
    "#print(len(newX_pca[0]))\n",
    "#print(round(np.mean(newX_pca_std),2))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae11035",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(newX.todense())==1000\n",
    "assert len(newX.todense()[0])==1\n",
    "assert round(np.mean(newX_std),2)==0\n",
    "assert len(newX_pca)==1000\n",
    "assert len(newX_pca[0])==300\n",
    "assert round(np.mean(newX_pca_std),2)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165d1f44",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q3 [10 points]: Building models using original set of features\n",
    "\n",
    "<ul>\n",
    "    <li>Use standardized data of original set of features ('newX_std') and class labels (`y`) to first perform train_test_split using `test_size`=0.3, `random_state`=10 to obtain X_train, X_test, y_train, y_test corresponding to training data of features, testing data of features, class labels for data points in training data, class labels for data points in testing data respectively.</li>\n",
    "    <li>Using `liblinear` as the solver, build a logistic regression model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_lg`. </li>\n",
    "    <li>Using max_depth=4, random_state=10, build a decision tree model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_dt`. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16675235",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "#Build logistic regression and decisiontree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### BEGIN SOLUTION \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(newX_std, y, test_size=0.3, random_state=10)\n",
    "\n",
    "lg = LogisticRegression(solver='liblinear')\n",
    "lg.fit(X_train, y_train)\n",
    "y_pred_lg = lg.predict(X_test)\n",
    "acc_lg = (accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=4, random_state=10)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_dt = (accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "#print(round(acc_lg, 2))\n",
    "#print(round(acc_dt, 2))\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391e5e4",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "3",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(acc_lg, 2)==0.77\n",
    "assert round(acc_dt, 2)<=0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5eda23",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Q4 [10 points]: Building models using top-300 principal component features\n",
    "\n",
    "<ul>\n",
    "    <li>Use standardized data of modified features as the top-300 principal components (`newX_pca_std`) and class labels (`y`) to first perform train_test_split using `test_size`=0.3, `random_state`=10 to obtain X_train, X_test, y_train, y_test corresponding to training data of features, testing data of features, class labels for data points in training data, class labels for data points in testing data respectively.</li>\n",
    "    <li>Using `liblinear` as the solver, build a logistic regression model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_pca_lg`. </li>\n",
    "    <li>Using max_depth=4, random_state=10, build a decision tree model using training data and compute its accuracy using testing data. Assign accuracy value to variable `acc_pca_dt`. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b680d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Please do not create or delete any cells\n",
    "\n",
    "#Build logistic regression and decisiontree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(newX_pca_std, y, test_size=0.3, random_state=10)\n",
    "\n",
    "lg = LogisticRegression(solver='liblinear')\n",
    "lg.fit(X_train, y_train)\n",
    "y_pred_lg = lg.predict(X_test)\n",
    "acc_pca_lg = (accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=4, random_state=10)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "acc_pca_dt = (accuracy_score(y_test, y_pred_lg))\n",
    "\n",
    "print(round(acc_pca_lg, 2))\n",
    "print(round(acc_pca_dt, 2))\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc04ca",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "4",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert round(acc_pca_lg, 2)<=0.80\n",
    "assert round(acc_pca_dt, 2)<=0.80"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
