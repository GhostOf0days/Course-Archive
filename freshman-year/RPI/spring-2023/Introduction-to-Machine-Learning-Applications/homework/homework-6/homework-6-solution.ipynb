{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "liked-tractor",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Desc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Homework-6\n",
    "##### Total number of points: 40\n",
    "#### Due date: March 31st, 2023\n",
    "\n",
    "Before you submit this homework, make sure everything runs as expected. First, restart the kernel (in the menu, select Kernel → Restart) and then run all cells (in the menubar, select Cell → Run All). You can discuss with others regarding the homework but all work must be your own.\n",
    "\n",
    "This homework will test your knowledge on basics of Python. The Python notebooks shared will be helpful to solve these problems. \n",
    "\n",
    "Steps to evaluate your solutions:\n",
    "\n",
    "Step-1: Ensure you have installed Anaconda (Windows: https://docs.anaconda.com/anaconda/install/windows/ ; Mac:https://docs.anaconda.com/anaconda/install/mac-os/ ; Linux: https://docs.anaconda.com/anaconda/install/linux/)\n",
    "\n",
    "Step-2: Open the Jupyter Notebook by first launching the anaconda software console\n",
    "\n",
    "Step-3: Open the .ipynb file and write your solutions at the appropriate location \"# YOUR CODE HERE\"\n",
    "\n",
    "Step-4: You can restart the kernel and click run all (in the menubar, select Cell → Run All) on the center-right on the top of this window.\n",
    "\n",
    "Step-5: Now go to \"File\" then click on \"Download as\" then click on \"Notebook (.ipynb)\" Please DO NOT change the file name and just keep it as .ipynb file format\n",
    "\n",
    "Step-6: Go to lms.rpi.edu and upload your homework at the appropriate link to submit this homework.\n",
    "\n",
    "#### Please note that for any question in this assignment you will receive points ONLY if your solution passes all the test cases including hidden testcases as well. So please make sure you try to think all possible scenarios before submitting your answers.  \n",
    "- Note that hidden tests are present to ensure you are not hardcoding. \n",
    "- If caught cheating: \n",
    "    - you will receive a score of 0 for the 1st violation. \n",
    "    - for repeated incidents, you will receive an automatic 'F' grade and will be reported to the dean of Lally School of Management. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expired-density",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR  CGPA  \\\n",
       "0           1        337          118                  4  4.5  4.5  9.65   \n",
       "1           2        324          107                  4  4.0  4.5  8.87   \n",
       "2           3        316          104                  3  3.0  3.5  8.00   \n",
       "3           4        322          110                  3  3.5  2.5  8.67   \n",
       "4           5        314          103                  2  2.0  3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit  \n",
       "0         1             0.92  \n",
       "1         1             0.76  \n",
       "2         1             0.72  \n",
       "3         1             0.80  \n",
       "4         0             0.65  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/lmanikon/lmanikon.github.io/master/teaching/datasets/KaggleAdmissions.csv')\n",
    "df.columns=['Serial No.', 'GRE Score', 'TOEFL Score', 'University Rating', 'SOP',\n",
    "       'LOR', 'CGPA', 'Research', 'Chance of Admit']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-niagara",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q1 [18 points]\n",
    "\n",
    "#### 1. Create a new dataframe `df_sub`, that is a copy of `df` and drop the column `Serial No.` \n",
    "\n",
    "#### 2. Standardize only these attributes in `df_sub` using the function `RobustScaler()`: \n",
    "- `GRE Score`, `TOEFL Score`\n",
    "\n",
    "#### 3. Perform normalization only on these attributes in `df_sub` using the function `StandardScaler()`\n",
    "- `University Rating`, `SOP`, `LOR`, `CGPA`, `Research` \n",
    "    \n",
    "#### Note that after steps 3 and 4, make sure you still have the transformed values saved in `df_sub` \n",
    "\n",
    "#### 4. Create a new column named `Admit` using original column `Chance of Admit ` to create a discrete set of class labels using these conditions. Then drop `Chance of Admit ` column from `df_sub`. \n",
    "- Convert to 2, if `Chance of Admit` value is `>= 0.65`\n",
    "- 1, if `Chance of Admit` value is `< 0.65`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "precious-enhancement",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q1-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Answering the above questions in the same order as listed\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn import preprocessing \n",
    "\n",
    "\n",
    "df_sub = df.drop(columns=['Serial No.'])\n",
    "colnames=list(df_sub.columns)\n",
    "\n",
    "df_sub[['GRE Score', 'TOEFL Score']]=preprocessing.RobustScaler().fit_transform(df_sub[['GRE Score', 'TOEFL Score']])\n",
    "df_sub[[ 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research']]=preprocessing.StandardScaler().fit_transform(df_sub[[ 'University Rating', 'SOP', 'LOR', 'CGPA', 'Research']])\n",
    "\n",
    "bins=np.array([0,0.65,1.0])\n",
    "df_sub['Admit'] = np.digitize(df['Chance of Admit'], bins)\n",
    "df_sub = df_sub.drop(columns=['Chance of Admit'])\n",
    "\n",
    "#print(len(df_sub))\n",
    "#print(len(df_sub.columns))\n",
    "#print(set(df_sub.columns))\n",
    "\n",
    "#print(round(np.mean(df_sub['CGPA']), 2))\n",
    "#print(round(np.std(df_sub['CGPA']), 2))\n",
    "#print(round(np.mean(df_sub['TOEFL Score']), 2))\n",
    "\n",
    "\n",
    "#print(round(np.sum(df_sub['Admit']), 2))\n",
    "#print(set(df_sub['Admit']))\n",
    "#print(len(df_sub['Admit'].loc[df_sub['Admit']==1]))\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "laughing-increase",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "1",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#[6 points] Test cell-1\n",
    "#DO NOT MODIFY/DELETE THIS CELL \n",
    "assert (len(df_sub))==400\n",
    "assert (len(df_sub.columns))==8\n",
    "assert (set(df_sub.columns))=={'LOR', 'SOP', 'CGPA', 'TOEFL Score', 'GRE Score', 'Research', 'Admit', 'University Rating'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smart-shoot",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "2",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#[6 points] Test cell-2\n",
    "#DO NOT MODIFY/DELETE THIS CELL \n",
    "assert (round(np.mean(df_sub['CGPA']), 2))==0.0\n",
    "assert (round(np.std(df_sub['CGPA']), 2))==1.0\n",
    "assert (round(np.mean(df_sub['TOEFL Score']), 2))==0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "formed-childhood",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "3",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#[6 points] Test cell-3\n",
    "#DO NOT MODIFY/DELETE THIS CELL \n",
    "assert (round(np.sum(df_sub['Admit']), 2))==687\n",
    "assert (set(df_sub['Admit']))=={1, 2}\n",
    "assert (len(df_sub['Admit'].loc[df_sub['Admit']==1]))==113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-sister",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q2 [15 points]\n",
    "#### 1. Split the data saved in the dataframe in Question-1 (`df_sub`) into `X` and `y` for feature columns and class label column respectively. \n",
    "- Feature columns (X): `GRE Score`, `TOEFL Score`, `University Rating`, `SOP`, `LOR`, `CGPA`, `Research` \n",
    "- CLass label column (y): `Admit`\n",
    "\n",
    "#### 2. Using `X` and `y` variables representing features and class labels, perform train_test_split operation to build training (`X_train`, `y_train`) and testing data (`X_test`, `y_test`). \n",
    "- Use test_size=0.4, random_state=55 as the parameters for train_test_split() function. \n",
    "\n",
    "#### 3. Train the randomforest classifier (initialized as variable `rf`) using these parameters: max_depth=7, random_state=23. \n",
    "- Using the trained model `rf` to first compute accuracy score and assign it to variable `acc_rf`. \n",
    "- Then compute the impurity-based feature importances.\n",
    "- Append the names of these top-3 features to a list `impFeatures`. Please make sure you type the feature names exactly as in `df_sub` \n",
    "\n",
    "#### 4. Train a K-Nearest Neighbors classifier (initialized as variable `knn1` and `knn2`) using these parameters: n_neighbors=5 and n_neighbors=20 and the `kd_tree` algorithm.\n",
    "- Using the trained models `knn1` and `knn2` on training data, compute the accuracy score using test data and assign that to variables `acc_knn_5` and `acc_knn_22` respectively for `k=2` and `k=22`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "precious-minnesota",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q2-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Answering the above questions in the same order as listed\n",
    "\n",
    "impFeatures=[]\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X = df_sub.drop(columns=['Admit'])\n",
    "y = df_sub['Admit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=55)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=7, random_state=23)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "#print(rf.max_depth)\n",
    "#print(rf.n_estimators)\n",
    "#print(round(acc_rf,2))\n",
    "\n",
    "colnames = list(X.columns)\n",
    "fts  = dict(zip(colnames, rf.feature_importances_))\n",
    "import operator\n",
    "sorted_op = sorted(fts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "for i in range(3):\n",
    "    impFeatures.append(sorted_op[i][0])\n",
    "\n",
    "#print(set(impFeatures))\n",
    "\n",
    "knn1 = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "knn1.fit(X_train, y_train)\n",
    "y_pred_knn1 = knn1.predict(X_test)\n",
    "acc_knn_5 = accuracy_score(y_test, y_pred_knn1)\n",
    "#print(knn1.metric)\n",
    "#print(round(acc_knn_4,2))\n",
    "\n",
    "\n",
    "knn2 = KNeighborsClassifier(n_neighbors=22, algorithm='kd_tree')\n",
    "knn2.fit(X_train, y_train)\n",
    "y_pred_knn2 = knn2.predict(X_test)\n",
    "acc_knn_22 = accuracy_score(y_test, y_pred_knn2)\n",
    "#print(knn1.metric)\n",
    "#print(round(acc_knn_20, 2))\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "black-server",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "4",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#[8 points] Test cell-4\n",
    "#DO NOT MODIFY/DELETE THIS CELL \n",
    "assert (rf.max_depth)==7\n",
    "assert (rf.n_estimators)==100\n",
    "#assert round(acc_rf,2)==0.9\n",
    "assert round(acc_rf,2)<=0.9\n",
    "assert set(impFeatures)=={'GRE Score', 'CGPA', 'TOEFL Score'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "improving-topic",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "5",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#[6 points] Test cell-5\n",
    "#DO NOT MODIFY/DELETE THIS CELL \n",
    "assert knn1.algorithm==\"kd_tree\"\n",
    "assert knn1.algorithm==\"kd_tree\"\n",
    "assert (round(acc_knn_5,2))<=0.87\n",
    "assert (round(acc_knn_22, 2))<=0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-affiliate",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Q3 [10 points]\n",
    "\n",
    "#### 1. Assign your response to this string variable `your_response1` explaining why there is a performance difference between `knn1` and `knn2` models that were trained with neighbors `4` and `20` respectively? Justify. \n",
    "#### 2. Include your response in this variable `your_response2` describing if this is a reasonable way to perform normalization? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "anticipated-merchant",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "Q3-Sol",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "your_response1=\" \"\n",
    "your_response2=\" \"\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "your_response1=\" Larger the value of k, better the accuracy \"\n",
    "\n",
    "your_response2 = \"It is interesting but somehow the model that standardizes the entire data might perform better than this \"\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "filled-cornell",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "6",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#[8 points] Hidden Test cell-6\n",
    "#DO NOT MODIFY/DELETE THIS CELL \n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(your_response1)>4\n",
    "assert len(your_response2)>4\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
